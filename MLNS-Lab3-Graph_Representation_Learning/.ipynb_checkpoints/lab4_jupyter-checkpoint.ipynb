{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Network Science Analytics\n",
    "Lab 4: Network representation learning\n",
    "March 13, 2020\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "from helper import *\n",
    "import os\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.sparse import *\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read network files\n",
    "karate = nx.read_gml(\"./karate.gml\")\n",
    "cora = nx.read_gml(\"./cora.gml\")\n",
    "\n",
    "# Choose a network\n",
    "G = \n",
    "print(\"The number of nodes: {}\".format(G.number_of_nodes()))\n",
    "print(\"The number of edges: {}\".format(G.number_of_edges()))\n",
    "\n",
    "# Get the node community labels and the number of communities\n",
    "node2comm, num_of_communities = get_node2community(g=G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Network Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1: Implementation of a random walking strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_walks(graph, N, L):\n",
    "    '''\n",
    "    :param graph: networkx graph\n",
    "    :param N: the number of walks for each node\n",
    "    :param L: the walk length\n",
    "    :return walks: the list of walks\n",
    "    '''\n",
    "    nodelist = list(graph.nodes())\n",
    "    walks = []\n",
    "    \n",
    "\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "        \n",
    "    return walks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2: Learning representations of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_walks=\n",
    "walk_length=\n",
    "embedding_size = \n",
    "window_size = \n",
    "output_filename=\"./graph.embedding\"\n",
    "\n",
    "# Perform random walks\n",
    "walks = perform_random_walks(graph=G, N=num_of_walks, L=walk_length)\n",
    "# Learn representations of nodes\n",
    "model = Word2Vec(walks, size=embedding_size, sg=1, window=window_size, min_count=0, workers=3)\n",
    "# Save the embedding vectors\n",
    "model.wv.save_word2vec_format(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.4: Visualization of embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(graph=G, node2embedding=model.wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Link Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(graph, train_set_ratio):\n",
    "        \n",
    "    # --- Step 0: The graph must be connected ---\n",
    "    if nx.is_connected(G) is not True:\n",
    "        raise ValueError(\"The graph contains more than one connected component!\")\n",
    "        \n",
    "    # --- Step 1: Generate positive edge samples for testing set ---\n",
    "    residual_g = graph.copy()\n",
    "    test_pos_samples = []\n",
    "      \n",
    "    # Shuffle the list of edges\n",
    "    edges = list(residual_g.edges())\n",
    "    np.random.shuffle(edges)\n",
    "\n",
    "    test_set_size = int((1.0 - train_set_ratio) * graph.number_of_edges())\n",
    "    num_of_pos_test_samples = 0\n",
    "    ##################################\n",
    "    \n",
    "    Please complete here\n",
    "    \n",
    "    ##################################\n",
    "    # Check if we have the desired number of positive samples for testing set \n",
    "    if num_of_pos_test_samples != test_set_size:\n",
    "        raise ValueError(\"Enough positive edge samples could not be found!\")\n",
    "\n",
    "    # --- Step 2: Generate positive edge samples for training set ---\n",
    "    # The remaining edges are simply considered for positive samples of the training set\n",
    "    train_pos_samples = list(residual_g.edges())\n",
    "        \n",
    "    # --- Step 3: Generate the negative samples for testing and training sets ---\n",
    "    non_edges = list(nx.non_edges(graph))\n",
    "    np.random.shuffle(non_edges)\n",
    "\n",
    "    train_neg_samples = non_edges[:test_set_size]\n",
    "    test_neg_samples = non_edges[test_set_size:test_set_size*2]\n",
    "\n",
    "    # --- Step 4: Combine sample lists and create corresponding labels ---\n",
    "    # For training set\n",
    "    train_samples = train_pos_samples + train_neg_samples\n",
    "    train_labels = [1 for _ in train_pos_samples] + [0 for _ in train_neg_samples]\n",
    "    # For testing set\n",
    "    test_samples = test_pos_samples + test_neg_samples\n",
    "    test_labels = [1 for _ in test_pos_samples] + [0 for _ in test_neg_samples]\n",
    "    \n",
    "    return residual_g, train_samples, train_labels, test_samples, test_labels\n",
    "    \n",
    "def edge_prediction(node2embedding, train_samples, test_samples, feature_func=None):\n",
    "    \n",
    "    # --- Construct feature vectors for edges ---\n",
    "    if feature_func is None:\n",
    "        feature_func = lambda x,y: abs(x-y)\n",
    "        \n",
    "    train_features = [feature_func(node2embedding[edge[0]], node2embedding[edge[1]]) for edge in train_samples]\n",
    "    test_features = [feature_func(node2embedding[edge[0]], node2embedding[edge[1]]) for edge in test_samples]\n",
    "    \n",
    "    # --- Build the model and train it ---\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    train_preds = clf.predict_proba(train_features)[:, 1]\n",
    "    test_preds = clf.predict_proba(test_features)[:, 1]\n",
    "\n",
    "    # --- Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from predictions ---\n",
    "    fpr, tpr, _ = roc_curve(test_labels, test_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, color='darkred', label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='lightgray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training and testing sets\n",
    "residual_g, train_samples, train_labels, test_samples, test_labels = generate_samples(graph=G, train_set_ratio=0.5)\n",
    "# Perform random walks over the residual network\n",
    "num_of_walks, walk_length, window_size, embedding_size = (, , , )\n",
    "residual_walks = perform_random_walks(graph=residual_g, N=num_of_walks, L=walk_length)\n",
    "# Learn representations of nodes\n",
    "model = Word2Vec(walks, size=embedding_size, sg=1, window=window_size, min_count=0, workers=3)\n",
    "# Perform the edge prediction and plot the ROC curve\n",
    "edge_prediction(model.wv, train_samples, test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Node Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classification(graph=G, train_set_ratio=0.5, node2embedding=model.wv, number_of_shuffles=10)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part IV: Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 4.1: Implementation of spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(G, k):\n",
    "    '''\n",
    "    :param G: given graph\n",
    "    :param k: the number of clusters\n",
    "    :return node2embedding: a dictionary whose keys are nodes and values are the corresponding embeddings\n",
    "    '''\n",
    "\n",
    "\n",
    "    return node2embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.2: Visualization of embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = \n",
    "node2embedding = spectral_clustering(G, k=embedding_size)\n",
    "visualize(graph=G, node2embedding=node2embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
